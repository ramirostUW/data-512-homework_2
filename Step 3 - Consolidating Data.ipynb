{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.1",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "extensions": {
            "azuredatastudio": {
                "version": 1,
                "views": []
            }
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Step 3 - Consolidating Data\n",
                "\n",
                "This notebook is designed to consolidate ORES article evaluation data, and U.S. population data, into a single file. It takes in the output of the Step 2 notebook, which consists of thousands of JSON files that each have an individual ORES evaluation as well as metadata on the article that was evaluated. It also takes inÂ  the static files: an Excel file containing population data for U.S. states, named \"NST-EST2022-POP.xslx\" (this file can be downloaded from the website for the [U.S. Census Bureau](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html)), a CSV file containing a list of Wikipedia city articles and what state they correspond to, called \"us\\_cities\\_by\\_state\\_SEPT.2023.csv\" (the same file used as input for the Step 1 notebook, although its code didn't use the state column data), and an Excel file containing information about which regional division a state belongs to, called \"US States by Region - US Census Bureau.xlsx\"."
            ],
            "metadata": {
                "azdata_cell_guid": "e2dc7bf7-4798-4ada-9112-a1e72dbc89a0"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell defines constants and imports the notebook will use\n",
                "import os, json\n",
                "import pandas as pd\n",
                "\n",
                "ores_files_path = \"raw_api_data/ores/\"\n",
                "cities_by_state_path = \"input/us_cities_by_state_SEPT.2023.csv\"\n",
                "states_by_region_path = \"input/US States by Region - US Census Bureau.xlsx\"\n",
                "excel_path = 'input/NST-EST2022-POP.xlsx'\n",
                "output_path = \"refined_data/wp_scored_city_articles_by_state.csv\""
            ],
            "metadata": {
                "azdata_cell_guid": "6bf1539f-d6d1-4654-a15d-f61893cb3df6",
                "tags": []
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell takes in all three static tabular data files, and joins them\n",
                "#together into one Pandas Dataframe\n",
                "\n",
                "#Importing list of Wikipedia city articles and their states\n",
                "cities_by_state_data = pd.read_csv(cities_by_state_path)\n",
                "\n",
                "#Importing State population Data\n",
                "raw_excel = pd.read_excel(excel_path, index_col=0, header = 3)\n",
                "raw_excel_length, raw_excel_width = raw_excel.shape\n",
                "excel_data = raw_excel.iloc[0:(raw_excel_length - 7), ]\n",
                "excel_data = excel_data.rename(columns={'Unnamed: 1': 'April 1, 2020 Estimates Base'})\n",
                "excel_data['Geographic Area'] = excel_data.index.values\n",
                "labels = list(range(excel_data.shape[0]))\n",
                "excel_data.index = labels\n",
                "\n",
                "\n",
                "#Fixing the state name columns in both previous DataFrames so they match, and\n",
                "#then joining them by state name\n",
                "def fix_state_names(state_string):\n",
                "    newstring = state_string\n",
                "    if state_string[0] == '.':\n",
                "        newstring = state_string[1:]\n",
                "    \n",
                "    newstring = newstring.replace(\"_(U.S._state)\", \"\")\n",
                "    newstring = newstring.replace(\"_\", \" \")\n",
                "    \n",
                "    return newstring   \n",
                "excel_data['Geographic Area'] = [fix_state_names(x) for x in list(excel_data['Geographic Area'])]\n",
                "cities_by_state_data['state'] = [fix_state_names(x) for x in list(cities_by_state_data['state'])]\n",
                "joined_static_data = cities_by_state_data.join(excel_data.set_index('Geographic Area'), on='state')\n",
                "joined_static_data = joined_static_data[joined_static_data['April 1, 2020 Estimates Base'].notna()]\n",
                "\n",
                "#Grabbing the state grouping data, and then joining it with the previous joined DataFrame\n",
                "states_by_region = pd.read_excel(states_by_region_path, header = 0)\n",
                "states_by_region['is_state'] = states_by_region['STATE'].notna()\n",
                "states_by_region = states_by_region.fillna(method='ffill')\n",
                "states_by_region = states_by_region[states_by_region['is_state']]\n",
                "joined_static_data = joined_static_data.join(states_by_region.set_index('STATE'), on='state')\n",
                "joined_static_data = joined_static_data[joined_static_data['REGION'].notna()]\n",
                "joined_static_data"
            ],
            "metadata": {
                "azdata_cell_guid": "932f2532-2d3c-4ec2-b3d5-15e42b153326"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "         state           page_title  \\\n0      Alabama   Abbeville, Alabama   \n1      Alabama  Adamsville, Alabama   \n2      Alabama     Addison, Alabama   \n3      Alabama       Akron, Alabama   \n4      Alabama   Alabaster, Alabama   \n...        ...                  ...   \n22152  Wyoming   Wamsutter, Wyoming   \n22153  Wyoming   Wheatland, Wyoming   \n22154  Wyoming     Worland, Wyoming   \n22155  Wyoming      Wright, Wyoming   \n22156  Wyoming       Yoder, Wyoming   \n\n                                                     url  \\\n0       https://en.wikipedia.org/wiki/Abbeville,_Alabama   \n1      https://en.wikipedia.org/wiki/Adamsville,_Alabama   \n2         https://en.wikipedia.org/wiki/Addison,_Alabama   \n3           https://en.wikipedia.org/wiki/Akron,_Alabama   \n4       https://en.wikipedia.org/wiki/Alabaster,_Alabama   \n...                                                  ...   \n22152   https://en.wikipedia.org/wiki/Wamsutter,_Wyoming   \n22153   https://en.wikipedia.org/wiki/Wheatland,_Wyoming   \n22154     https://en.wikipedia.org/wiki/Worland,_Wyoming   \n22155      https://en.wikipedia.org/wiki/Wright,_Wyoming   \n22156       https://en.wikipedia.org/wiki/Yoder,_Wyoming   \n\n       April 1, 2020 Estimates Base       2020       2021       2022 REGION  \\\n0                         5024356.0  5031362.0  5049846.0  5074296.0  South   \n1                         5024356.0  5031362.0  5049846.0  5074296.0  South   \n2                         5024356.0  5031362.0  5049846.0  5074296.0  South   \n3                         5024356.0  5031362.0  5049846.0  5074296.0  South   \n4                         5024356.0  5031362.0  5049846.0  5074296.0  South   \n...                             ...        ...        ...        ...    ...   \n22152                      576837.0   577605.0   579483.0   581381.0   West   \n22153                      576837.0   577605.0   579483.0   581381.0   West   \n22154                      576837.0   577605.0   579483.0   581381.0   West   \n22155                      576837.0   577605.0   579483.0   581381.0   West   \n22156                      576837.0   577605.0   579483.0   581381.0   West   \n\n                 DIVISION  is_state  \n0      East South Central      True  \n1      East South Central      True  \n2      East South Central      True  \n3      East South Central      True  \n4      East South Central      True  \n...                   ...       ...  \n22152            Mountain      True  \n22153            Mountain      True  \n22154            Mountain      True  \n22155            Mountain      True  \n22156            Mountain      True  \n\n[22157 rows x 10 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>page_title</th>\n      <th>url</th>\n      <th>April 1, 2020 Estimates Base</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>is_state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Abbeville, Alabama</td>\n      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n      <td>5024356.0</td>\n      <td>5031362.0</td>\n      <td>5049846.0</td>\n      <td>5074296.0</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Adamsville, Alabama</td>\n      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n      <td>5024356.0</td>\n      <td>5031362.0</td>\n      <td>5049846.0</td>\n      <td>5074296.0</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>Addison, Alabama</td>\n      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n      <td>5024356.0</td>\n      <td>5031362.0</td>\n      <td>5049846.0</td>\n      <td>5074296.0</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Akron, Alabama</td>\n      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n      <td>5024356.0</td>\n      <td>5031362.0</td>\n      <td>5049846.0</td>\n      <td>5074296.0</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Alabaster, Alabama</td>\n      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n      <td>5024356.0</td>\n      <td>5031362.0</td>\n      <td>5049846.0</td>\n      <td>5074296.0</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22152</th>\n      <td>Wyoming</td>\n      <td>Wamsutter, Wyoming</td>\n      <td>https://en.wikipedia.org/wiki/Wamsutter,_Wyoming</td>\n      <td>576837.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>581381.0</td>\n      <td>West</td>\n      <td>Mountain</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22153</th>\n      <td>Wyoming</td>\n      <td>Wheatland, Wyoming</td>\n      <td>https://en.wikipedia.org/wiki/Wheatland,_Wyoming</td>\n      <td>576837.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>581381.0</td>\n      <td>West</td>\n      <td>Mountain</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22154</th>\n      <td>Wyoming</td>\n      <td>Worland, Wyoming</td>\n      <td>https://en.wikipedia.org/wiki/Worland,_Wyoming</td>\n      <td>576837.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>581381.0</td>\n      <td>West</td>\n      <td>Mountain</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22155</th>\n      <td>Wyoming</td>\n      <td>Wright, Wyoming</td>\n      <td>https://en.wikipedia.org/wiki/Wright,_Wyoming</td>\n      <td>576837.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>581381.0</td>\n      <td>West</td>\n      <td>Mountain</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22156</th>\n      <td>Wyoming</td>\n      <td>Yoder, Wyoming</td>\n      <td>https://en.wikipedia.org/wiki/Yoder,_Wyoming</td>\n      <td>576837.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>581381.0</td>\n      <td>West</td>\n      <td>Mountain</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>22157 rows Ã 10 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 2,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell loops every individual JSON file generated by the Step 2 Notebook,\n",
                "#and combines them all into one Dataframe, keeping only the three fields\n",
                "#needed for the final data file. \n",
                "\n",
                "file_list = os.listdir(ores_files_path)\n",
                "#file_list = file_list[1:5]\n",
                "ores_dataframe = []\n",
                "for filename in file_list:\n",
                "    json_path = ores_files_path + filename\n",
                "    file = open(json_path)\n",
                "    example_json = json.load(file)\n",
                "    file.close()\n",
                "    request_info = example_json['request_info']\n",
                "    lastrevid = request_info['lastrevid']\n",
                "    prediction = example_json['scores'][str(lastrevid)]['articlequality']['score']['prediction']\n",
                "    new_list_object = {\n",
                "        'article_title': request_info['page_title'],\n",
                "        'lastrevid' : lastrevid,\n",
                "        'article_quality': prediction\n",
                "    }\n",
                "    #print(request_info['page_title'])\n",
                "    ores_dataframe.append(new_list_object)\n",
                "ores_dataframe = pd.DataFrame(ores_dataframe)\n",
                "print(ores_dataframe)"
            ],
            "metadata": {
                "azdata_cell_guid": "4fc140fc-ee81-4702-8fd8-4e3dc05d9c05"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "                             article_title   lastrevid article_quality\n0                   Princes Lakes, Indiana  1019560872            Stub\n1      Montrose Charter Township, Michigan   101989287            Stub\n2                        Holcomb, New York  1024625267            Stub\n3                     Moyie Springs, Idaho  1032509578               C\n4                          Kilauea, Hawaii  1036838051            Stub\n...                                    ...         ...             ...\n21514                         Omao, Hawaii   965363482            Stub\n21515                    Chicago, Illinois   967239270            Stub\n21516                      Waikane, Hawaii   982615222            Stub\n21517      Kailua, Honolulu County, Hawaii   985095782            Stub\n21518               Matoaka, West Virginia   999751661               C\n\n[21519 rows x 3 columns]\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell joins the ORES data with the static data and filters out all non-city article rows\r\n",
                "#and unneeded columns, and then exports the much cleaner resuling DataFrame as a CSV\r\n",
                "\r\n",
                "ores_static_join = ores_dataframe.join(joined_static_data.set_index('page_title'), on='article_title')\r\n",
                "ores_static_join = ores_static_join[ores_static_join['REGION'].notna()]\r\n",
                "ores_static_join = ores_static_join.drop_duplicates() \r\n",
                "ores_static_join = ores_static_join[ores_static_join['url'] != \"https://en.wikipedia.org/wiki/Population\"] \r\n",
                "ores_static_join = ores_static_join[ores_static_join['url'] != \"https://en.wikipedia.org/wiki/Square_mile\"] \r\n",
                "ores_static_join = ores_static_join[ores_static_join['url'] != \"https://en.wikipedia.org/wiki/County_(United_States)\"] \r\n",
                "ores_static_join = ores_static_join[ores_static_join['url'] != \"https://en.wikipedia.org/wiki/2010_United_States_census\"] \r\n",
                "ores_static_join = ores_static_join[ores_static_join['url'] != \"https://en.wikipedia.org/wiki/2020_United_States_census\"] \r\n",
                "\r\n",
                "wp_scored_city_articles_by_state = pd.DataFrame({\r\n",
                "    \"state\": ores_static_join['state'],\r\n",
                "    \"regional_division\": ores_static_join['DIVISION'],\r\n",
                "    \"population\": ores_static_join[2022],\r\n",
                "    \"article_title\": ores_static_join['article_title'],\r\n",
                "    \"revision_id\": ores_static_join['lastrevid'],\r\n",
                "    \"article_quality\": ores_static_join['article_quality']\r\n",
                "})\r\n",
                "\r\n",
                "wp_scored_city_articles_by_state.to_csv(output_path, index=False)"
            ],
            "metadata": {
                "azdata_cell_guid": "855160e7-9930-4047-8395-96402ba71ed2"
            },
            "outputs": [],
            "execution_count": 4
        }
    ]
}