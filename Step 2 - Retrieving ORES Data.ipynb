{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.1",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "extensions": {
            "azuredatastudio": {
                "version": 1,
                "views": []
            }
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Step 2 - Retrieving ORES Data\n",
                "\n",
                "This short notebook is designed to query ORES, a model that that rates Wikpedia articles' quality and was trained on user-made evaluations, for its predictions regarding the quality of articles on American cities. As input, it takes in the individual JSON files obtained by the Step 1 notebook, and it outputs another set of individual JSONs containing all of the ORES results, as well as the data used to make ORES requests."
            ],
            "metadata": {
                "azdata_cell_guid": "7b2a4eff-3ea7-4009-8fc6-768d7ceb84b0"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#This simple cell takes in the list of files in the output folder of Step 1\r\n",
                "import os\r\n",
                "pageInfo_files_path = \"raw_api_data/Pageinfo/\"\r\n",
                "file_list = os.listdir(pageInfo_files_path)"
            ],
            "metadata": {
                "azdata_cell_guid": "c65fafef-1c30-43b6-9a6b-6e043e8b0118"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "#this cell loops through the list of files in Step 1's output folder\r\n",
                "#and makes a list of dicts containing all the relevant article revIDs from each JSON\r\n",
                "#that we can use to make ORES requests, as well as additional useful fields. \r\n",
                "\r\n",
                "import json \r\n",
                "\r\n",
                "revid_list = []\r\n",
                "#file_list = ['Abbeville, Alabama.json']\r\n",
                "for filename in file_list:\r\n",
                "    json_path = pageInfo_files_path + filename\r\n",
                "    file = open(json_path)\r\n",
                "    example_json = json.load(file)\r\n",
                "    file.close()\r\n",
                "\r\n",
                "    pages_object = example_json['query']['pages']\r\n",
                "\r\n",
                "    for page in pages_object:\r\n",
                "        page = (pages_object[page])#['lastrevid'])\r\n",
                "        #print(page['title'])\r\n",
                "        new_list_object = {\r\n",
                "            'page_title': page['title'],\r\n",
                "            'lastrevid' : page['lastrevid'],\r\n",
                "            'url': page['canonicalurl'],\r\n",
                "            'touched': page['touched']\r\n",
                "        }\r\n",
                "        revid_list.append(new_list_object)\r\n",
                "\r\n",
                "#print(revid_list)\r\n",
                "\r\n",
                "with open((\"revid_list.json\"), \"w\") as outfile:\r\n",
                "        json.dump(revid_list, outfile)\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "932f2532-2d3c-4ec2-b3d5-15e42b153326"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "The below code was was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program, and made available under the [Creative a Commons](https://creativecommons.org/) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 14, 2023, and defines a function and accompanying constants needed to query ORES for the article quality evaluation for an individual revid. The username and Access Token constants were modified to use my Wikimedia account and Personal Access Token."
            ],
            "metadata": {
                "azdata_cell_guid": "b617bc7d-45b9-458f-9e89-4834d1574b70"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import time, requests, json\r\n",
                "\r\n",
                "#########\r\n",
                "#\r\n",
                "#    CONSTANTS\r\n",
                "#\r\n",
                "\r\n",
                "#    The current LiftWing ORES API endpoint and prediction model\r\n",
                "#\r\n",
                "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\r\n",
                "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\r\n",
                "\r\n",
                "#\r\n",
                "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\r\n",
                "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\r\n",
                "#\r\n",
                "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\r\n",
                "API_THROTTLE_WAIT = (60.0/5000.0)-API_LATENCY_ASSUMED\r\n",
                "\r\n",
                "#    When making automated requests we should include something that is unique to the person making the request\r\n",
                "#    This should include an email - your UW email would be good to put in there\r\n",
                "#    \r\n",
                "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\r\n",
                "#    as part of the header too\r\n",
                "#\r\n",
                "REQUEST_HEADER_TEMPLATE = {\r\n",
                "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2023\",\r\n",
                "    'Content-Type': 'application/json',\r\n",
                "    'Authorization': \"Bearer {access_token}\"\r\n",
                "}\r\n",
                "#\r\n",
                "#    This is a template for the parameters that we need to supply in the headers of an API request\r\n",
                "#\r\n",
                "REQUEST_HEADER_PARAMS_TEMPLATE = {\r\n",
                "    'email_address' : \"\",         # your email address should go here\r\n",
                "    'access_token'  : \"\"          # the access token you create will need to go here\r\n",
                "}\r\n",
                "\r\n",
                "#\r\n",
                "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\r\n",
                "#\r\n",
                "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\r\n",
                "\r\n",
                "#\r\n",
                "#    This is a template of the data required as a payload when making a scoring request of the ORES model\r\n",
                "#\r\n",
                "ORES_REQUEST_DATA_TEMPLATE = {\r\n",
                "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\r\n",
                "    \"rev_id\":      \"\",       # this request requires a revision id\r\n",
                "    \"features\":    True\r\n",
                "}\r\n",
                "\r\n",
                "#\r\n",
                "#    These are used later - defined here so they, at least, have empty values\r\n",
                "#\r\n",
                "USERNAME = \"RamirostUW\"\r\n",
                "ACCESS_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiIyZjgzODVmMTA5NTQ2YWQ1YTdhYTJhZDhmOGI0M2E1YiIsImp0aSI6Ijc4MWEwM2FhNzg4ZjhiN2M1YmJlNGM0YzM4NjkzYjcwNzA0NzIxNGVkMGNhN2UyMmUwOGZlZWRjNWQyNGJhZDlhNDgzYWNmZmVhNzU3YzY1IiwiaWF0IjoxNjk3NDkxNzQ5LjY4NjIxMSwibmJmIjoxNjk3NDkxNzQ5LjY4NjIxNCwiZXhwIjozMzI1NDQwMDU0OS42ODM4OCwic3ViIjoiNzQwMjEwMzEiLCJpc3MiOiJodHRwczovL21ldGEud2lraW1lZGlhLm9yZyIsInJhdGVsaW1pdCI6eyJyZXF1ZXN0c19wZXJfdW5pdCI6NTAwMCwidW5pdCI6IkhPVVIifSwic2NvcGVzIjpbImJhc2ljIl19.qdG1zzLz4s4ECRRYtjz0tje9SNnDG6oYzIHjq1wtdyoSYXrCkC2J81RJygW8_QelGL-4mGaC7GPBoHWhFD12rhDfpbW1A_ZDncF9oPFeXmZLno9oJEi2rCDBEzWpn5rqW2UUCKI-d_Sl15XixwkxWfvM4GkAdMqR892csJmB6aW1gIf89QvqqvKJQKza1uaJw4zARK3qPF5S2Tgwv45oaGQw3MYOdsiaLpQrRFLTXhQ1YdaWLz4e3EimwimTEFJ74jlWKIfHEfns-fATMCJPyiqut0xh9Ctdg9KesCaPYOuEz-7ec_xbE0adcvFY5GBUCsu7zKZXmqbIW8F6Mnj3Mz3tUeeEBD3QW7SLJhwkMokTnAKCeY23yjCF4ukCG-6aUigBZkzdK6zb-5wwFpwEzrTFASIqLzmGN4XKE1pps8jDV3MIkjt7Kxdvvxu3jRTO2KlGGZLEzHrKI2bm55Nlh3s_SvNuT-BxfU9mH29ofvSiD8zHqjFm9HeAX-ylRRAre0_vAvlMpMBd8U044aKFZ970csHjYdO2cxTbUx64aaRsM9KxF2A6wXwRzj3-8VOyLnm74CwkbgVZ4Enh14nOOVgYQ__uZ1jFTjh8xi8N3bm-pS9hFGzECt1-skKaaDRX-f8oyMCQC9lN4gYphM7GCw6kmU7aszu7hYNi3WccBmk\"\r\n",
                "#\r\n",
                "\r\n",
                "#########\r\n",
                "#\r\n",
                "#    PROCEDURES/FUNCTIONS\r\n",
                "#\r\n",
                "\r\n",
                "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\r\n",
                "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \r\n",
                "                                   model_name = API_ORES_EN_QUALITY_MODEL, \r\n",
                "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \r\n",
                "                                   header_format = REQUEST_HEADER_TEMPLATE, \r\n",
                "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\r\n",
                "    \r\n",
                "    #    Make sure we have an article revision id, email and token\r\n",
                "    #    This approach prioritizes the parameters passed in when making the call\r\n",
                "    if article_revid:\r\n",
                "        request_data['rev_id'] = article_revid\r\n",
                "    if email_address:\r\n",
                "        header_params['email_address'] = email_address\r\n",
                "    if access_token:\r\n",
                "        header_params['access_token'] = access_token\r\n",
                "    \r\n",
                "    #   Making a request requires a revision id - an email address - and the access token\r\n",
                "    if not request_data['rev_id']:\r\n",
                "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\r\n",
                "    if not header_params['email_address']:\r\n",
                "        raise Exception(\"Must provide an 'email_address' value\")\r\n",
                "    if not header_params['access_token']:\r\n",
                "        raise Exception(\"Must provide an 'access_token' value\")\r\n",
                "    \r\n",
                "    # Create the request URL with the specified model parameter - default is a article quality score request\r\n",
                "    request_url = endpoint_url.format(model_name=model_name)\r\n",
                "    \r\n",
                "    # Create a compliant request header from the template and the supplied parameters\r\n",
                "    headers = dict()\r\n",
                "    for key in header_format.keys():\r\n",
                "        headers[str(key)] = header_format[key].format(**header_params)\r\n",
                "    \r\n",
                "    # make the request\r\n",
                "    try:\r\n",
                "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\r\n",
                "        # occurs during the request processing - throttling is always a good practice with a free data\r\n",
                "        # source like ORES - or other community sources\r\n",
                "        if API_THROTTLE_WAIT > 0.0:\r\n",
                "            time.sleep(API_THROTTLE_WAIT)\r\n",
                "        #response = requests.get(request_url, headers=headers)\r\n",
                "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\r\n",
                "        json_response = response.json()\r\n",
                "    except Exception as e:\r\n",
                "        print(e)\r\n",
                "        json_response = None\r\n",
                "    return json_response\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "154e9248-41dd-4ebe-b807-9bc33c9ad8ce"
            },
            "outputs": [],
            "execution_count": 15
        },
        {
            "cell_type": "code",
            "source": [
                "#This line creates a duplicate reference for the list of article data dicts\r\n",
                "#we will use to query ORES\r\n",
                "original_revid_list = revid_list"
            ],
            "metadata": {
                "azdata_cell_guid": "295afbb9-2de5-41e4-8d89-ca595490c235"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell scans the output folder for the ORES JSONs that the next cell outputs, and filters\r\n",
                "#out all of the articles for which existing ORES data was found in order to not download it again. \r\n",
                "#This was made because the ORES download loop was prone to returning errors and takes a long time to \r\n",
                "#run, and this allows it to resume where it left off. \r\n",
                "\r\n",
                "import os\r\n",
                "ores_files_path = \"raw_api_data/ores/\"\r\n",
                "revid_list = original_revid_list\r\n",
                "existing_file_list = os.listdir(ores_files_path)\r\n",
                "existing_file_list = [sub.replace('.json', '') for sub in existing_file_list]\r\n",
                "print(len(revid_list))\r\n",
                "\r\n",
                "def already_downloaded(revid_object):\r\n",
                "    return(existing_file_list.count(str(revid_object['lastrevid'])) == 0)\r\n",
                "\r\n",
                "filtered_revid_list = [revid_object for revid_object in revid_list if already_downloaded(revid_object)]\r\n",
                "\r\n",
                "print(len(filtered_revid_list))\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "f25dab6b-0d6b-49e4-8c45-3a142f44041a"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "21519\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "0\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 30
        },
        {
            "cell_type": "code",
            "source": [
                "#This cell loops through a list of article data dicts that includes a revid \r\n",
                "#and queries ORES for its article quality evaluation of that revid.\r\n",
                "#It then stores the article quality data, as well as the input dict the list read in,\r\n",
                "#to an individual JSON file named after the revid.\r\n",
                "\r\n",
                "\r\n",
                "ores_data_folder = \"raw_api_data/ores/\"\r\n",
                "ores_json = []\r\n",
                "#revid_list = revid_list[0:5]\r\n",
                "for revid_object in filtered_revid_list:\r\n",
                "    try:\r\n",
                "        revid = revid_object['lastrevid']\r\n",
                "            #print(revid_object['page_title'])\r\n",
                "        score = request_ores_score_per_article(article_revid= revid ,#ARTICLE_REVISIONS[article_title],\r\n",
                "                                        email_address=\"dwmc@uw.edu\",\r\n",
                "                                        access_token=ACCESS_TOKEN)\r\n",
                "        score_data = score['enwiki']\r\n",
                "        score_data['request_info'] = revid_object\r\n",
                "        with open((ores_data_folder +  str(revid_object['lastrevid']) + \".json\"), \"w\") as outfile:\r\n",
                "             json.dump(score_data, outfile)\r\n",
                "        # ores_json.append(score_data)\r\n",
                "    \r\n",
                "    except Exception as exception:\r\n",
                "        print(exception)\r\n",
                "        print(\"Error on \" + revid_object['page_title'] + \", revid: \" + str(revid_object['lastrevid']))\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "fd776880-601c-4b91-bd14-fa497145beb8",
                "tags": []
            },
            "outputs": [],
            "execution_count": 29
        }
    ]
}